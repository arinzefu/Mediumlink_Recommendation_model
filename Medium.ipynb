{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:06.870926300Z",
     "start_time": "2023-11-23T08:00:06.338773Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('medium-data-science-articles-2020.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:07.913791100Z",
     "start_time": "2023-11-23T08:00:06.872931900Z"
    }
   },
   "id": "e246e766bf763298"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 url  \\\n0  https://towardsdatascience.com/making-python-p...   \n1  https://towardsdatascience.com/how-to-be-fancy...   \n2  https://uxdesign.cc/how-exactly-do-you-find-in...   \n3  https://towardsdatascience.com/from-scratch-to...   \n4  https://www.cantorsparadise.com/the-waiting-pa...   \n\n                                               title            author  \\\n0              Making Python Programs Blazingly Fast      martin.heinz   \n1                        How to be fancy with Python           dipam44   \n2  How exactly do you find insights from qualitat...   taylornguyen144   \n3  From scratch to search: playing with your data...  stanislavprihoda   \n4  The Waiting Paradox: An Intro to Probability D...        maikeelisa   \n\n                                        author_page  \\\n0      https://towardsdatascience.com/@martin.heinz   \n1           https://towardsdatascience.com/@dipam44   \n2              https://uxdesign.cc/@taylornguyen144   \n3  https://towardsdatascience.com/@stanislavprihoda   \n4       https://www.cantorsparadise.com/@maikeelisa   \n\n                                            subtitle   claps  responses  \\\n0  Let’s look at the performance of our Python pr...  3300.0          3   \n1      Python tricks that will make your life easier  1700.0         12   \n2               Visualizing the synthesis processes…  1100.0          3   \n3                              One Pipeline to rule…   232.0          1   \n4          How much longer do I have to wait for my…   859.0          5   \n\n   reading_time           tag        date  \n0             5  Data Science  2020-01-01  \n1             5  Data Science  2020-01-01  \n2             4  Data Science  2020-01-01  \n3             9  Data Science  2020-01-01  \n4             8  Data Science  2020-01-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>title</th>\n      <th>author</th>\n      <th>author_page</th>\n      <th>subtitle</th>\n      <th>claps</th>\n      <th>responses</th>\n      <th>reading_time</th>\n      <th>tag</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://towardsdatascience.com/making-python-p...</td>\n      <td>Making Python Programs Blazingly Fast</td>\n      <td>martin.heinz</td>\n      <td>https://towardsdatascience.com/@martin.heinz</td>\n      <td>Let’s look at the performance of our Python pr...</td>\n      <td>3300.0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>Data Science</td>\n      <td>2020-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://towardsdatascience.com/how-to-be-fancy...</td>\n      <td>How to be fancy with Python</td>\n      <td>dipam44</td>\n      <td>https://towardsdatascience.com/@dipam44</td>\n      <td>Python tricks that will make your life easier</td>\n      <td>1700.0</td>\n      <td>12</td>\n      <td>5</td>\n      <td>Data Science</td>\n      <td>2020-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://uxdesign.cc/how-exactly-do-you-find-in...</td>\n      <td>How exactly do you find insights from qualitat...</td>\n      <td>taylornguyen144</td>\n      <td>https://uxdesign.cc/@taylornguyen144</td>\n      <td>Visualizing the synthesis processes…</td>\n      <td>1100.0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>Data Science</td>\n      <td>2020-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://towardsdatascience.com/from-scratch-to...</td>\n      <td>From scratch to search: playing with your data...</td>\n      <td>stanislavprihoda</td>\n      <td>https://towardsdatascience.com/@stanislavprihoda</td>\n      <td>One Pipeline to rule…</td>\n      <td>232.0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>Data Science</td>\n      <td>2020-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.cantorsparadise.com/the-waiting-pa...</td>\n      <td>The Waiting Paradox: An Intro to Probability D...</td>\n      <td>maikeelisa</td>\n      <td>https://www.cantorsparadise.com/@maikeelisa</td>\n      <td>How much longer do I have to wait for my…</td>\n      <td>859.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>Data Science</td>\n      <td>2020-01-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:07.962659200Z",
     "start_time": "2023-11-23T08:00:07.919773Z"
    }
   },
   "id": "e6da6a33e9b67f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(108021, 10)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.022563Z",
     "start_time": "2023-11-23T08:00:07.950691400Z"
    }
   },
   "id": "cb6c4e6f88b5e001"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = data.drop('author_page', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.124808200Z",
     "start_time": "2023-11-23T08:00:07.975626300Z"
    }
   },
   "id": "c81a2fefef279f64"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = df.drop('reading_time', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.129795500Z",
     "start_time": "2023-11-23T08:00:07.994574100Z"
    }
   },
   "id": "5b87b2fc7bee6ef8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(108021, 8)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.131790300Z",
     "start_time": "2023-11-23T08:00:08.011590200Z"
    }
   },
   "id": "df2326fad0608c33"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tag_counts = data['tag'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.132787600Z",
     "start_time": "2023-11-23T08:00:08.036524100Z"
    }
   },
   "id": "44303e2982530b30"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tag\nData Science              45320\nMachine Learning          25539\nArtificial Inteligence    15764\nData                      10103\nBig Data                   4210\nDeep Learning              3815\nAnalytics                  3270\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.132787600Z",
     "start_time": "2023-11-23T08:00:08.043505500Z"
    }
   },
   "id": "b464207c9e057326"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count per Column:\n",
      "url              0\n",
      "title            0\n",
      "author           0\n",
      "subtitle     69435\n",
      "claps            0\n",
      "responses        0\n",
      "tag              0\n",
      "date             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Missing Values Count per Column:\")\n",
    "print(missing_values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.133785800Z",
     "start_time": "2023-11-23T08:00:08.057468600Z"
    }
   },
   "id": "e5bb3464bb666523"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "data = data.fillna(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.222068700Z",
     "start_time": "2023-11-23T08:00:08.088385900Z"
    }
   },
   "id": "61e829ec3f5b8922"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count per Column:\n",
      "url          0\n",
      "title        0\n",
      "author       0\n",
      "subtitle     0\n",
      "claps        0\n",
      "responses    0\n",
      "tag          0\n",
      "date         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Missing Values Count per Column:\")\n",
    "print(missing_values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:08.241020100Z",
     "start_time": "2023-11-23T08:00:08.170690100Z"
    }
   },
   "id": "43d584ed5cb28ab"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:12.054629700Z",
     "start_time": "2023-11-23T08:00:08.200623400Z"
    }
   },
   "id": "336992f8d4f8f25c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:12.534491300Z",
     "start_time": "2023-11-23T08:00:12.058621500Z"
    }
   },
   "id": "2b8405c0b2b5cd53"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data['text'] = (\n",
    "    data['title'].astype(str) + \" \" +\n",
    "    data['subtitle'].astype(str) + \" \" +\n",
    "    data['tag'].astype(str) + \" \" +\n",
    "    data['author'].astype(str)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:12.674163500Z",
     "start_time": "2023-11-23T08:00:12.537484200Z"
    }
   },
   "id": "73174b187fb3dbb8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:12.692114500Z",
     "start_time": "2023-11-23T08:00:12.676156300Z"
    }
   },
   "id": "9d87a15399ae133a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "# Normalize numeric features\n",
    "numeric_features = ['claps', 'responses']\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "text_embeddings = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:12.725230800Z",
     "start_time": "2023-11-23T08:00:12.694108400Z"
    }
   },
   "id": "cb2cc435847e0898"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:00:13.880617200Z",
     "start_time": "2023-11-23T08:00:12.722231Z"
    }
   },
   "id": "e3ac3e70e050b84d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "for index, row in data.iterrows():\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(row['text'], padding=\"max_length\", truncation=True, max_length=32, return_tensors='pt')\n",
    "    \n",
    "    input_ids = tokenized['input_ids']\n",
    "    attention_mask = tokenized['attention_mask']\n",
    "\n",
    "    # Forward pass through the BertModel\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Extract the embeddings\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # numeric features\n",
    "    numeric_features_array = row[numeric_features].values.astype(float)  \n",
    "    numeric_features_tensor = torch.tensor(numeric_features_array, dtype=torch.float32)\n",
    "    \n",
    "    # Concatenate\n",
    "    combined_embedding = torch.cat((embeddings.squeeze(), numeric_features_tensor))\n",
    "\n",
    "    # Convert to numpy and append to the list\n",
    "    text_embeddings.append(combined_embedding.numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single NumPy array\n",
    "text_embeddings = np.array(text_embeddings)\n",
    "\n",
    "# Convert the NumPy array to a torch tensor\n",
    "text_embeddings = torch.tensor(text_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:18:51.159148100Z",
     "start_time": "2023-11-23T08:00:13.885606700Z"
    }
   },
   "id": "cf361a4ba8b18491"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1512, -0.0150,  0.4095,  ...,  0.0179, 12.8987,  1.4714],\n        [ 0.1384, -0.1223,  0.1262,  ...,  0.0268,  6.5005,  6.4594],\n        [-0.1321,  0.0858,  0.6481,  ..., -0.0470,  4.1012,  1.4714],\n        ...,\n        [-0.1844, -0.0774,  0.3101,  ...,  0.1542, -0.2976, -0.1913],\n        [-0.1561,  0.2101,  0.3557,  ..., -0.0642, -0.2976, -0.1913],\n        [-0.0727,  0.1133,  0.2001,  ...,  0.1017, -0.2976, -0.1913]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:18:51.272361Z",
     "start_time": "2023-11-23T10:18:51.184081500Z"
    }
   },
   "id": "59f3e9b09b235f99"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "num_urls = len(data['url'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:18:51.363956900Z",
     "start_time": "2023-11-23T10:18:51.275352900Z"
    }
   },
   "id": "e4479bc5e2549c0a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(text_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:18:51.382624200Z",
     "start_time": "2023-11-23T10:18:51.366949700Z"
    }
   },
   "id": "476a95c87c4c3ea4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:18:51.434597Z",
     "start_time": "2023-11-23T10:18:51.385612900Z"
    }
   },
   "id": "efe24f17f2f2bd72"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# The model\n",
    "class RecommendationModel(nn.Module):\n",
    "    def __init__(self, input_size, num_urls):\n",
    "        super(RecommendationModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_urls)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        scores = self.fc(embeddings.squeeze(dim=1))\n",
    "        return scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:59:27.236148200Z",
     "start_time": "2023-11-23T10:59:27.205055900Z"
    }
   },
   "id": "5f5f0be8209badfe"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:51:49.922094700Z",
     "start_time": "2023-11-23T10:51:49.898157400Z"
    }
   },
   "id": "9063306dd4a362a9"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "input_size = text_embeddings.size(1)\n",
    "recommendation_model = RecommendationModel(input_size, num_urls)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:59:31.560810Z",
     "start_time": "2023-11-23T10:59:30.871839800Z"
    }
   },
   "id": "ca6b52f5881ee73b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecommendationModel(\n",
      "  (fc): Linear(in_features=770, out_features=107971, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(recommendation_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:59:42.233559700Z",
     "start_time": "2023-11-23T10:59:42.216059100Z"
    }
   },
   "id": "7673f1ab6a044fdc"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(recommendation_model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:09:23.528091300Z",
     "start_time": "2023-11-23T11:09:23.484445200Z"
    }
   },
   "id": "655c6a6d00e9e1db"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 - Number of Embeddings: 1\n",
      "Embeddings (first few): [tensor([[ 1.5117e-01, -1.4954e-02,  4.0948e-01,  ...,  1.7921e-02,\n",
      "          1.2899e+01,  1.4714e+00],\n",
      "        [ 1.3840e-01, -1.2232e-01,  1.2619e-01,  ...,  2.6786e-02,\n",
      "          6.5005e+00,  6.4594e+00],\n",
      "        [-1.3212e-01,  8.5801e-02,  6.4806e-01,  ..., -4.7015e-02,\n",
      "          4.1012e+00,  1.4714e+00],\n",
      "        ...,\n",
      "        [ 2.3730e-01,  1.5199e-01,  4.0307e-01,  ...,  2.1543e-01,\n",
      "          1.5028e-01,  3.6291e-01],\n",
      "        [ 2.9161e-02, -1.1290e-02,  3.4831e-01,  ...,  1.5476e-02,\n",
      "          8.2209e-01, -1.9132e-01],\n",
      "        [ 1.6088e-01, -1.3701e-01,  2.4973e-01,  ...,  2.7411e-01,\n",
      "          4.7419e-01, -1.9132e-01]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    embeddings = batch\n",
    "    \n",
    "    print(f\"Batch {batch_idx + 1} - Number of Embeddings: {len(embeddings)}\")\n",
    "    \n",
    "    print(\"Embeddings (first few):\", embeddings[:5])\n",
    "    \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T10:57:41.560119100Z",
     "start_time": "2023-11-23T10:57:41.546122700Z"
    }
   },
   "id": "3b3180c05014bd6b"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6752/6752 [1:28:49<00:00,  1.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 53671.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6752/6752 [1:28:17<00:00,  1.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average Loss: 53071.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6752/6752 [1:31:59<00:00,  1.22batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average Loss: 52515.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Training loop \n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    recommendation_model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')):\n",
    "        # Extract embeddings\n",
    "        embeddings = batch[0]\n",
    "\n",
    "        # Forward pass\n",
    "        scores = recommendation_model(embeddings)\n",
    "\n",
    "        # Generate random negative samples \n",
    "        negative_samples = torch.randint(high=num_urls, size=scores.shape, dtype=torch.long)\n",
    "\n",
    "        # Calculate pairwise ranking loss\n",
    "        loss = nn.MarginRankingLoss(margin=1.0)(scores, negative_samples, torch.ones_like(scores))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    \n",
    "    average_loss = total_loss / (batch_idx + 1) \n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:38:35.008999300Z",
     "start_time": "2023-11-23T11:09:28.833806600Z"
    }
   },
   "id": "ad68f19c5405b7ec"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(recommendation_model.state_dict(), 'recommendation_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:41:21.558190400Z",
     "start_time": "2023-11-23T15:41:18.176352200Z"
    }
   },
   "id": "3bba4a96b11a2110"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "RecommendationModel(\n  (fc): Linear(in_features=770, out_features=107971, bias=True)\n)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:58:28.034281600Z",
     "start_time": "2023-11-23T15:58:27.975370700Z"
    }
   },
   "id": "7a713351dbfb2e69"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell 5590 i7\\AppData\\Local\\Temp\\ipykernel_12004\\2690060934.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  text_embeddings = torch.tensor(text_embeddings_list)\n"
     ]
    }
   ],
   "source": [
    "input_text = \"learning python\"\n",
    "\n",
    "# Tokenize input text\n",
    "tokenized = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=32, return_tensors='pt')\n",
    "\n",
    "# Extract input_ids and attention_mask\n",
    "input_ids = tokenized['input_ids']\n",
    "attention_mask = tokenized['attention_mask']\n",
    "\n",
    "# Forward pass through the BertModel\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Extract the embeddings\n",
    "embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Include numeric features\n",
    "combined_embedding = embeddings.squeeze()\n",
    "\n",
    "# Convert to NumPy and append to the list\n",
    "text_embeddings_list = []\n",
    "text_embeddings_list.append(combined_embedding.numpy())\n",
    "\n",
    "# Convert the list of embeddings to a single NumPy array\n",
    "text_embeddings = torch.tensor(text_embeddings_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:10:27.249563700Z",
     "start_time": "2023-11-23T16:10:27.105103700Z"
    }
   },
   "id": "d3b267debd6ecc26"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.2375e-02, -1.7897e-01,  2.8450e-01,  9.4814e-02,  1.8734e-01,\n          5.4046e-02, -8.2771e-02, -1.5231e-01,  5.3404e-02, -1.8147e-01,\n         -9.3207e-02,  1.1508e-01,  5.9534e-02,  4.5949e-01,  4.7271e-02,\n          1.0773e-01, -1.3453e-01,  1.3300e-01, -3.8646e-02, -1.9102e-01,\n          1.9086e-02, -3.9585e-02,  2.0024e-01, -1.2829e-01,  1.5668e-02,\n          1.5647e-01,  4.0626e-02, -1.7340e-01, -5.8690e-01,  1.4192e-01,\n         -1.7934e-01,  1.8025e-02,  1.3375e-01,  2.2254e-01, -2.8376e-01,\n         -3.8096e-01, -4.5037e-01, -2.0124e-01, -8.5111e-02, -3.6500e-01,\n          2.8822e-01,  8.2506e-03, -5.5807e-02,  9.2722e-02, -2.4299e-01,\n         -5.6173e-02, -3.9782e-01,  2.4925e-01, -3.1232e-01, -1.2396e-01,\n         -5.9616e-02,  7.1030e-02,  3.1310e-01,  1.0595e-01,  2.8439e-02,\n          3.1939e-01,  1.0818e-01, -1.4935e-01,  1.9614e-01,  9.8527e-02,\n          3.0562e-01, -1.0174e-01,  4.3365e-01,  1.9365e-01,  1.8735e-01,\n         -3.8077e-01,  1.5204e-01,  2.2810e-01, -2.8618e-01,  1.6931e-01,\n          1.3149e-01,  2.5727e-01,  1.4648e-01, -1.9691e-01, -9.1593e-02,\n         -1.3239e-01, -3.3910e-02,  1.5009e-01,  5.0571e-01,  3.4763e-01,\n          1.7127e-01,  1.8271e-01, -6.2451e-02,  8.3709e-02,  8.5608e-05,\n          1.8407e-01, -5.7730e-02,  7.7562e-02, -2.5889e-01, -1.8530e-02,\n          1.7119e-01, -2.2098e-02,  1.3038e-01, -3.3979e-02,  5.5268e-03,\n         -2.0373e-01, -1.1730e-01, -1.9506e-01, -1.4087e-02,  2.6687e-02,\n         -4.6866e-01,  1.8829e-01, -6.8940e-01,  3.5670e-02, -7.7105e-02,\n         -9.4962e-02, -3.2656e-01,  2.4365e-01,  1.5354e-01, -1.1604e-01,\n         -2.0038e-01, -2.4388e-02,  1.6362e-01,  1.9258e-01, -5.1495e-02,\n          2.7395e-01, -7.9111e-03, -5.2186e-02,  2.0084e-01,  2.0765e-01,\n          2.2487e-01,  9.5508e-02, -1.5451e-01,  4.0246e-01,  7.8645e-02,\n          1.3896e-01, -5.2571e-02, -6.9303e-02, -1.2842e-01, -1.1885e-01,\n          8.6555e-02, -1.8735e-01, -4.1609e-02, -2.3350e-02,  4.1114e-02,\n         -2.7754e-02, -5.0612e-02, -2.4780e-01,  4.1570e-01, -2.8460e-01,\n         -2.2132e-01,  1.0272e-01, -1.3098e-01, -2.1769e-01,  9.9712e-02,\n         -2.0372e-01,  1.0160e-01, -9.1395e-02, -3.3600e-01,  2.4786e-01,\n         -9.4815e-02,  1.7524e-01,  8.8511e-02, -3.7939e-02, -2.9578e-01,\n         -1.7260e-01,  2.9144e-01, -3.2024e-01,  1.7680e-02,  2.7980e-01,\n          4.8007e-01,  1.5034e-01,  2.0368e-01, -4.2521e-02, -2.4032e-01,\n         -3.1279e-01, -1.8208e-01,  3.0729e-01, -3.5424e-02, -3.1519e-01,\n         -2.1486e-01, -3.3536e-01,  2.7973e-01,  4.7668e-02,  1.5546e-01,\n          3.6716e-01, -1.8861e-01, -3.0596e-01, -4.9016e-02,  8.1814e-03,\n         -3.7022e-01,  4.1427e-01, -1.8634e-01, -1.4707e-01,  1.0220e-02,\n          2.2034e-01, -5.3588e-02, -6.7816e-02,  5.1333e-01,  1.3933e-01,\n         -3.4076e-01, -2.2724e-01,  1.9852e-01, -1.3427e-01,  1.4332e-01,\n         -1.7331e-01, -2.4183e-01, -9.9195e-02,  1.6094e-01,  2.0577e-02,\n          6.8483e-02, -2.0403e-01,  5.2325e-02,  8.9898e-02,  6.2382e-02,\n          2.0297e-01, -5.5506e-02, -1.1435e-01, -6.4587e-02, -1.0067e-01,\n         -2.7404e-01, -1.5647e-02,  5.1910e-01, -1.3294e-01,  3.1463e-01,\n         -1.8493e-01,  2.0975e-01, -9.9357e-02, -3.0030e-01,  3.4481e-01,\n          4.4782e-01, -3.3805e-02,  1.5953e-01,  1.4733e-01, -7.2426e-01,\n         -1.2764e-01, -2.3761e-03, -2.0591e-01,  2.1450e-01, -9.4947e-02,\n         -3.0877e-01,  2.2055e-01,  1.4870e-01, -1.7306e-01, -1.8891e-02,\n          3.8069e-01, -1.8763e-01, -1.1309e-01,  4.1620e-01,  2.0104e-01,\n         -2.7207e-03, -7.7976e-02,  3.6440e-01, -1.3666e-02,  3.7672e-01,\n          1.7199e-01,  1.3862e-01,  1.1930e-01, -3.4122e-02, -5.2146e-01,\n          2.2206e-01, -2.1649e-01, -3.5006e-01, -6.0460e-02, -3.3906e-02,\n         -1.9595e-01,  2.5094e-01,  4.4249e-02, -1.5288e-01,  9.9960e-02,\n         -4.5012e-02,  6.0888e-02,  1.7728e-01, -1.5721e-01,  3.4263e-01,\n          3.2504e-01,  2.9714e-01, -2.5374e-01,  4.2419e-01, -1.4312e-01,\n         -8.7682e-02, -7.6533e-02, -7.5412e-02,  1.1680e-01,  2.0963e-01,\n         -2.9942e-02,  4.6368e-01,  5.8684e-02,  6.3134e-02, -1.3791e-01,\n         -3.7765e-02, -9.5973e-02, -2.6086e-02, -3.5086e-01, -2.4142e-03,\n         -1.3007e-01, -1.3904e-01, -4.3206e-01, -1.4063e-01, -4.5288e-02,\n         -8.1731e-02,  2.7695e-01,  1.4066e-03,  2.0650e-01,  2.2896e-01,\n          2.2940e-01, -4.6631e-01,  6.4435e-02, -4.0434e-01,  1.5320e-01,\n         -2.6447e-01,  1.1933e-02, -2.4104e-01, -1.3471e-01,  2.2852e-01,\n          1.3763e-01, -1.6595e-01,  7.2839e-02, -6.3796e+00, -1.1913e-01,\n         -2.2343e-01, -3.7048e-01,  2.1135e-01, -2.2435e-01,  1.0583e-01,\n          1.4415e-01, -3.3930e-01,  4.0368e-02,  1.6040e-01, -3.3570e-01,\n          2.5650e-01,  7.8245e-03,  2.0057e-01,  3.8351e-01,  3.4041e-02,\n          2.6398e-01, -1.9050e-01,  1.6223e-02, -2.0728e-01, -3.0367e-01,\n         -1.9112e-01,  8.4715e-02,  4.0315e-02,  6.2677e-02,  2.1825e-01,\n          4.7434e-02, -6.3864e-01, -7.5062e-02, -2.0208e-01, -1.0859e-01,\n         -1.3490e-01,  3.1584e-01,  4.0566e-02, -2.0972e-01, -3.5211e-02,\n         -4.3330e-02,  1.7749e-01, -4.4706e-01,  5.1447e-02,  2.2030e-01,\n         -5.0615e-02, -3.5348e-02, -5.7857e-02, -3.8271e-01,  1.7109e-02,\n          1.6858e-01, -1.0972e-01, -2.0899e-01,  2.3231e-01,  6.8797e-02,\n          1.2042e-01, -1.4558e-01, -1.8005e-01, -4.4964e-02, -2.1240e-02,\n          7.5636e-03, -6.9040e-02,  8.3057e-02,  3.0499e-01,  1.0420e-01,\n          4.8744e-01,  1.7577e-01, -2.7851e-01, -1.1707e-01,  5.1072e-02,\n         -6.0846e-01,  1.0446e-01,  4.3644e-02, -7.0240e-02, -7.5107e-02,\n          1.6434e-01, -6.1332e-01, -1.9163e-01,  1.4236e-01,  1.3653e-01,\n         -1.2548e-01, -4.0902e-02,  2.5172e-02, -1.4206e-01,  2.7229e-01,\n          2.2753e-01,  1.8622e-01, -2.2816e-01, -2.4992e-01, -1.2534e-02,\n         -8.9459e-02, -2.5965e-01,  2.5431e-01,  2.4409e-02, -1.1868e-01,\n          3.2261e-01,  3.9665e-01, -3.4892e-02,  9.4446e-02,  3.2405e-01,\n         -9.5710e-02,  4.4793e-02,  8.9665e-02,  1.4848e-01, -1.3941e-01,\n          1.0501e-01, -2.0999e-01,  1.7788e-01,  4.6238e-02, -3.1020e-01,\n         -3.7439e-03,  2.4752e-01, -9.2905e-02, -9.5059e-02,  2.3985e-02,\n          2.5060e-01, -2.7391e-01,  2.1323e-01, -3.0185e-02, -1.9383e-01,\n          2.7649e-01,  4.1888e-03,  1.1771e-01, -5.5357e-02,  2.5663e-02,\n         -1.6390e-01, -1.6922e-01, -4.6996e-01,  3.2300e-02,  5.6218e-02,\n         -2.6234e-01, -3.1676e-01,  1.0213e-01, -5.1876e-02,  2.5428e-01,\n         -2.7358e-01, -3.1195e-01,  2.4761e-01,  1.1214e-01,  2.4434e-01,\n         -2.7990e-01,  2.2555e-01, -1.0171e-01,  1.0765e-01, -2.3188e-01,\n          5.7786e-02,  2.7235e-01,  7.6428e-02,  8.9661e-02, -5.7564e-02,\n          1.6090e-01,  4.8082e-02,  3.3183e-01,  2.2712e-02, -5.0568e-01,\n          4.8340e-01,  2.4002e-01, -2.3903e-01, -2.9988e-01,  1.0874e-01,\n         -2.7757e-01, -2.9489e-01,  5.6604e-02, -8.4314e-03, -1.6938e-01,\n          1.2944e-02,  2.2079e-01,  1.0003e-01,  1.2401e-01, -2.2958e-01,\n          3.0878e-01, -2.3201e-01,  4.2186e-01,  2.1123e-01,  2.3624e-02,\n         -4.6640e-01, -2.3345e-01,  1.2855e-02,  7.3130e-02,  5.9804e-02,\n         -8.0793e-03,  4.1483e-01,  3.5425e-01,  1.7222e-01, -2.9755e-02,\n          1.0717e-01,  3.6846e-01,  3.3928e-01, -3.8693e-02, -2.1041e-01,\n         -2.1868e-01, -2.8113e-02,  3.9132e-01, -1.6362e-01,  2.6841e-02,\n         -3.4211e-02, -1.7488e-02,  1.9110e-01, -3.4036e-01,  2.5050e-01,\n          6.0346e-02, -1.9879e-01,  4.9368e-01, -5.0496e-02, -6.4051e-02,\n         -1.1434e-01, -4.7260e-02,  1.4367e-01,  1.8153e-01,  2.7248e-01,\n          2.0226e-01,  1.3929e-02, -2.7250e-02, -7.1881e-02, -1.9749e-01,\n         -3.4467e-01, -5.4754e-02, -1.4509e-01,  1.6270e-01,  4.0071e-01,\n         -1.8561e-01, -3.0382e-01, -1.1248e-01, -2.1471e-01, -1.2944e-01,\n         -1.3148e-01,  2.4936e-03,  9.2410e-02,  4.5873e-01, -1.0182e-02,\n         -1.4429e-01,  6.7530e-02, -3.6432e-02,  1.7984e-01,  5.0228e-02,\n          1.0184e-01,  1.3089e-01,  3.2567e-01, -1.0534e-01, -1.9659e-01,\n         -7.1119e-02,  1.8377e-01, -1.2211e-01, -1.5386e-01, -5.7601e-01,\n         -2.9791e-01, -2.4939e-01,  1.3899e-01,  1.2963e-01,  6.4174e-02,\n          1.4976e-01,  5.7475e-01,  4.6932e-01, -1.1330e-01, -1.0636e-01,\n          1.6837e-01, -1.4158e-01,  2.5038e-01, -5.9575e-01,  4.0764e-01,\n         -1.2407e-01, -1.0382e-01,  3.9437e-01, -2.6592e-01,  2.9871e-01,\n         -2.0183e-02, -3.2848e-01,  5.2696e-02,  3.5208e-01, -1.5476e-01,\n         -7.2180e-02,  1.4357e-01,  1.8129e-01,  4.2170e-02,  9.2700e-02,\n          2.5831e-01,  2.3177e-01, -1.2988e-01, -2.3461e-01,  1.3435e-02,\n          6.9149e-02, -4.2130e-01, -2.0214e-01, -1.5827e-01,  1.7478e-01,\n         -4.1269e-02,  1.4818e-01,  2.2556e-01, -4.6136e-01, -1.7912e-01,\n         -1.1364e-01, -4.1397e-01,  6.6971e-02,  6.0028e-02,  2.6395e-01,\n         -2.8726e-01,  5.0860e-01, -2.4726e-01,  2.9959e-02,  1.5805e-01,\n         -1.5150e-01,  1.8001e-03,  3.3226e-01, -1.4729e-01,  1.6712e-01,\n          2.6589e-02,  2.6395e-01,  3.7195e-02,  9.7376e-02,  9.4855e-02,\n         -3.2365e-01, -9.4577e-02,  6.3858e-02, -2.3198e-01, -1.0574e-01,\n          2.3266e-01,  1.8194e-01, -7.2526e-02,  8.6721e-02,  1.2665e-01,\n         -3.2109e-02, -9.8469e-02, -3.5303e-01, -8.0521e-03,  5.2561e-02,\n          3.4633e-02, -1.2685e-01,  2.1930e-01,  1.4896e-01, -3.6187e-01,\n          7.0438e-02,  2.4804e-01,  1.2415e-01,  2.8256e-01,  1.4402e-01,\n         -4.3186e-02,  3.0819e-02,  2.9052e-01, -1.4835e-01,  1.9389e-02,\n         -2.6234e-01, -1.0017e-01,  3.9126e-01, -1.0205e-01, -1.1435e-01,\n         -2.3290e-01,  9.3630e-03, -1.2901e-01,  1.5941e-01,  5.1191e-02,\n         -4.0544e-01, -4.8242e-02,  5.6063e-02, -8.3847e-02,  7.5379e-02,\n         -2.0375e-01, -3.7462e-01, -8.8979e-02,  4.2139e-01, -2.7909e-02,\n          4.9063e-02,  1.9656e-03,  8.1583e-02,  1.3249e-01,  1.8930e-01,\n         -8.6688e-02,  1.7898e-01, -3.0477e-01,  2.5407e-02,  2.0439e-01,\n         -5.3713e-01,  6.3650e-02, -1.4285e-01, -4.6085e-02,  3.8616e-02,\n         -1.7635e-01,  3.1861e-01, -2.1831e-02,  2.6656e-01,  3.6588e-01,\n          1.0282e-01,  9.1943e-02, -1.1705e-01, -2.7683e-02, -2.8729e-01,\n         -8.2732e-02,  5.5870e-02,  3.6322e-01, -4.2360e-01,  1.3517e-01,\n         -2.8276e-02,  4.1238e-02, -2.0802e-01, -7.3980e-02, -7.6393e-02,\n          8.0535e-02,  1.9678e-01, -8.7453e-03, -1.2883e-01, -4.4066e-01,\n         -3.0575e-02,  4.5984e-03,  4.6721e-01,  6.1618e-02, -7.8209e-02,\n         -9.0807e-02,  4.8625e-02, -1.2225e-01, -1.4741e-01, -4.4000e-02,\n         -7.4308e-02, -2.9259e-01,  7.9654e-04,  9.3047e-02, -2.6322e-01,\n         -6.0216e-02,  3.2171e-01,  1.4327e-01,  6.0735e-03,  8.9477e-02,\n          4.4102e-01,  1.4660e-01, -2.3822e-01,  6.4309e-02, -2.4282e-01,\n          4.0352e-02,  1.0247e-01, -3.9020e-01,  1.2866e-01, -2.9321e-01,\n          1.2702e-01, -1.2777e-01,  2.4684e-01, -6.5765e-02,  2.0563e-01,\n          2.6328e-02,  1.6866e-01, -1.8280e-01,  8.9144e-02, -6.0906e-02,\n          5.1354e-02,  1.0686e-01, -9.2301e-02, -1.7644e-01, -9.1462e-02,\n          3.1198e-01,  9.4008e-02, -3.5594e-01,  1.3087e-02, -1.7958e-01,\n          1.6311e-01, -1.4597e-01, -8.7317e-02,  4.4353e-01, -4.1832e-02,\n          5.0081e-02,  1.2073e-01,  5.3109e-02, -3.6977e-01,  1.8000e-01,\n         -1.6431e-01,  4.6153e-02,  1.5861e-02]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:10:45.592314700Z",
     "start_time": "2023-11-23T16:10:45.438781800Z"
    }
   },
   "id": "53c6ea4cf06f56f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "recommendation_model.eval()\n",
    "\n",
    "# Initialize variables for evaluation\n",
    "total_loss = 0.0\n",
    "\n",
    "\n",
    "recommended_urls = []\n",
    "recommended_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')):\n",
    "        # Extract embeddings\n",
    "        embeddings = batch[0]\n",
    "\n",
    "        # Forward pass\n",
    "        scores = recommendation_model(embeddings)\n",
    "\n",
    "        \n",
    "        recommended_url_index = scores.argmax().item()\n",
    "\n",
    "        \n",
    "        recommended_url = data['url'].unique()[recommended_url_index]\n",
    "\n",
    "        # Append recommended URL and its score to the lists\n",
    "        recommended_urls.append(recommended_url)\n",
    "        recommended_scores.append(scores[0].item())  \n",
    "\n",
    "        # Generate random negative samples\n",
    "        negative_samples = torch.randint(high=num_urls, size=scores.shape, dtype=torch.long)\n",
    "\n",
    "        # Calculate pairwise ranking loss\n",
    "        loss = nn.MarginRankingLoss(margin=1.0)(scores, negative_samples, torch.ones_like(scores))\n",
    "\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "average_loss = total_loss / (batch_idx + 1)\n",
    "print(f'Evaluation Loss: {average_loss:.4f}')\n",
    "\n",
    "for url, score in zip(recommended_urls, recommended_scores):\n",
    "    print(f'Recommended URL: {url}, Score: {score:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca3081730f079b21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
